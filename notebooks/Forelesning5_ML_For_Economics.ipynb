{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Forelesning 5 - Bildeklassifisering**\n",
        "I denne forelesningen skal vi se nærmere på bruk av *bilder* som data, og hvordan vi kan gjøre binær bildeklassifikasjon. Denne notatboken går i hånd med kompendiumet, og fysiske forelesning om tema *Convolutional neural networks*."
      ],
      "metadata": {
        "id": "2XXT-38T4t9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Maskinlæring i samfunnsøkonomi\n",
        "Dette kurset har som formål å lære dere verktøy fra maskinlæring. Vi har diskutert lineær regresjon, logistisk regresjon, beslutningstrær, random forests, nevrale nettverk og ulike versjoner av sistnevnte.\n",
        "\n",
        "Maskinlæring har mange bruksområder innen samfunnsøkonomi, særlig fordi den kan analysere store mengder data, finne mønstre og gi oss prediksjoner.  \n",
        "\n",
        "## 1. Makroøkonomiske prognoser  \n",
        "- Forutsi BNP-vekst, inflasjon og arbeidsledighet ved å analysere store datasett med økonomiske indikatorer.  \n",
        "- Sentralbanker kan bruke maskinlæring for å tilpasse sine økonomiske avgjørelser.  \n",
        "\n",
        "## 2. Arbeidsmarked og lønnsdynamikk  \n",
        "- Analysere jobbmarkedet og forutsi arbeidsledighet basert på jobbutlysninger, sosiale medier og økonomiske data.  \n",
        "- Kartlegge hvordan automatisering påvirker sysselsetting i ulike sektorer.  \n",
        "\n",
        "## 3. Finansiell stabilitet og risikovurdering  \n",
        "- Oppdage økonomiske bobler ved å analysere finansmarkeder i sanntid.  \n",
        "- Identifisere systemiske risikoer i banker og finansinstitusjoner.  \n",
        "\n",
        "## 4. Skatteanalyse og svindeloppdagelse  \n",
        "- Forutsi skatteinntekter og optimalisere skattesystemet.  \n",
        "- Bruke algoritmer til å avdekke skattesvindel ved å analysere avvik i regnskapsdata.  \n",
        "\n",
        "## 5. Modellering av forbrukeratferd  \n",
        "- Analysere kjøpsmønstre og hvordan økonomiske faktorer påvirker forbruk.  \n",
        "- Utvikle mer treffsikre modeller for prisdynamikk og etterspørsel.  \n",
        "\n",
        "## 6. Evaluering av offentlige tiltak  \n",
        "- Måle effekten av ulike økonomiske politikktiltak (for eksempel subsidier eller velferdsordninger) ved å sammenligne store datasett før og etter implementering.  \n",
        "\n",
        "## 7. Handels- og investeringsanalyse  \n",
        "- Forutsi effekten av tollsatser, handelsavtaler og geopolitikk på økonomien.  \n",
        "- Analysere investeringstrender ved hjelp av alternative data, som satellittbilder og sentimentanalyse fra nyheter.  \n",
        "\n",
        "Maskinlæring kan altså gi økonomer et bedre verktøy for å forstå komplekse systemer og ta mer informerte beslutninger.  "
      ],
      "metadata": {
        "id": "fzeu7swZIU99"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bildeklassifisering i samfunnsøkonomi\n",
        "Bildeklassifisering med **Convolutional Neural Networks (CNN)** kan brukes i samfunnsøkonomi for å trekke innsikt fra visuelle data.  \n",
        "\n",
        "## 1. Økonomisk overvåking med satellittbilder  \n",
        "- **Måling av økonomisk aktivitet**: CNN kan analysere nattlys-satellittbilder for å estimere økonomisk vekst i ulike regioner.  \n",
        "- **Handelsvolum og forsyningskjeder**: Overvåke aktiviteten i havner og transportknutepunkter for å vurdere internasjonal handel.  \n",
        "- **Jordbruk og ressursforvaltning**: Predikere matproduksjon og økonomiske effekter av avlingssvikt ved analyse av satellittbilder.  \n",
        "\n",
        "## 2. Forbruksanalyse og detaljhandel  \n",
        "- **Kundeatferd i butikker**: Overvåke kundestrømmer i fysiske butikker for å optimalisere produktplassering og bemanning.  \n",
        "- **Kø- og trafikkmønstre**: CNN kan analysere trafikk- og parkeringsdata for å vurdere økonomisk aktivitet i ulike områder.  \n",
        "\n",
        "## 3. Arbeidsmarked og automatisering  \n",
        "- **Yrkesklassifisering via bilder**: CNN kan analysere bilder fra jobbsøkere for å kartlegge yrkesroller basert på arbeidsklær, verktøy og omgivelser.  \n",
        "\n",
        "## 4. Økonomisk krisehåndtering  \n",
        "- **Naturkatastrofer og økonomiske tap**: CNN kan evaluere skader fra flom, branner eller jordskjelv for å estimere økonomiske konsekvenser.  \n",
        "- **Flyktningstrømmer og migrasjon**: Bildeanalyse kan brukes for å overvåke bevegelsesmønstre ved humanitære kriser.  \n",
        "\n",
        "Ved å kombinere CNN med økonomiske data kan vi få dypere innsikt i hvordan visuelle signaler påvirker økonomiske beslutninger og trender.  \n",
        "___"
      ],
      "metadata": {
        "id": "nydLqMK5IaKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Eksempel - klassifisering av skip**\n",
        "I denne notatboken skal vi se hvordan vi kan implementere CNN til å klassifisere om en bilde av et skip er *militært skip* eller *sivilt skip*."
      ],
      "metadata": {
        "id": "KJRkzddR4__U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installere Dependencies og libraries\n",
        "Før vi kan begynne koden, trenger vi å installere noe bibliotek."
      ],
      "metadata": {
        "id": "-FTaVAVao7Tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n",
        "!pip install opencv-python # Computer vision modul\n",
        "!pip install matplotlib\n",
        "!pip list"
      ],
      "metadata": {
        "id": "vLn25KNV5HQ8",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensorflow\n",
        "Vi importerer TensorFlow for å kunne gjøre koden våre."
      ],
      "metadata": {
        "id": "8AC_rwJapDg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ],
      "metadata": {
        "id": "4c-rZ_hk5Ixv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Her kan vi sjekke hvor mange GPU'er vi har tilgjengelig. Dette kan vi endre i Google Colab ved å endre i \"Kjøring\" --> \"Endre kjøringstype\"."
      ],
      "metadata": {
        "id": "2ajjP8mdnYne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "gpus"
      ],
      "metadata": {
        "id": "ardMIPqnmigF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Neste linjer med kode er satt for å forhindre minneproblemer når vi kjører store maskinlæringsmodeller."
      ],
      "metadata": {
        "id": "9XdDF1LlnmgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avoid OOM errors (Out of memory) by setting GPU Memory Consumption Growth\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ],
      "metadata": {
        "id": "z5i4OS1h5P-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ],
      "metadata": {
        "id": "PaTwxYIW5S1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data\n",
        "Vi skal her se på bilder av militære (0) og sivile (1) båter/skip.\n",
        "Vi har masse data-eksempler i en mappe, og må *cleane* den for eventuelle dårlige bilder.\n",
        "\n",
        "### Hvorfor\n",
        "Et viktig prinsipp i maskinlæring er *shit in, shit out*. Da mener vi at hvis vi har dårlig data, vil modellen vår bli dårlig, noe som vil gi dårlig output av modellen."
      ],
      "metadata": {
        "id": "VSH-m5635W_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importerer noen essensielle bibliotek\n",
        "import cv2                        # For fargekonvertering, og computer-vision\n",
        "import imghdr                     # Modul som bestemmer hvilke type bilde som er i en fil - brukes for å cleane data.\n",
        "import matplotlib.pyplot as plt   # For plotting, vise bilder etc."
      ],
      "metadata": {
        "id": "AnIkN_9K5UIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hvordan hente data:\n",
        "I denne forelesningen vil vi gjennomgå hvordan vi lager en binær-bildeklassifiseringsmodell for å detektere om hva vi ser på bilde er **MILITÆR SKIP** eller **SIVILE SKIP**. Denne koden kan i prinsippet brukes for mange andre binære, bildeklassifiseringsmodeller - men hvor man kanskje må endre visse ting som nettverksarkitekturen.\n",
        "\n",
        "### Hente bilder fra internett\n",
        "1. Gå inn på Google Chrome, og last ned en \"Utvidelse\" (\"Extension\") som heter \"Download All Images\".\n",
        "2. Gå til Google, og skriv inn \"army ships\".\n",
        "3. Trykk på \"Utvidelser\" og trykk \"Download All Images\".\n",
        "4. Nå vil alle bildene lastes ned lokalt på PC/Mac'en din.\n",
        "5. Repeter steg 2 - 4, men ved å søke \"Civilian ships\".\n",
        "6. Lag en mappe som heter \"data-ships\", som inneholder to mapper: \"army\" og \"non-army\".\n",
        "7. Last opp \"data-ships\" mappen din i \"Min disk\" (\"MyDrive\") på Google drive.\n",
        "8. Nå er du klar for å kjøre koden under.\n",
        "\n",
        "\n",
        "Tips: Før du laster opp i Google Drive, kan det være lurt å fjerne de minste filene. F.eks. de som er under 10 kB, da de ofte er veldig små og kan by på problemer."
      ],
      "metadata": {
        "id": "SMfR2RkVoAXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Last data inn i Google Colab"
      ],
      "metadata": {
        "id": "ZoXgvl6vqtQi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the path to your folder\n",
        "data_dir = '/content/drive/MyDrive/data-ships'\n",
        "data_dir"
      ],
      "metadata": {
        "id": "JQB25y8D5tfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sjekker hvilke mapper som er inne i vårt *data_dir*"
      ],
      "metadata": {
        "id": "rjFVN4SOqysf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(data_dir)"
      ],
      "metadata": {
        "id": "p2qxwcWU5uBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Får en liste av sub-directories (foldere) som er en del av vår data_dir\n",
        "folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]\n",
        "\n",
        "# Teller files i hver mappe/foldere\n",
        "file_counts = {folder: len(os.listdir(os.path.join(data_dir, folder))) for folder in folders}\n",
        "\n",
        "# Print results\n",
        "for folder, count in file_counts.items():\n",
        "    print(f\"Folder '{folder}' contains {count} files.\")"
      ],
      "metadata": {
        "id": "_sqAydbNRJCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Her kan vi få opp alle filnavnene under mappen 'army'"
      ],
      "metadata": {
        "id": "UG4iymywsoEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(os.path.join(data_dir, 'army'))"
      ],
      "metadata": {
        "id": "YmccZkF-5vcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_exts = ['jpeg','jpg', 'bmp', 'png']"
      ],
      "metadata": {
        "id": "7b40t8yQsms_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(os.path.join(data_dir, 'army', '1647297548254.jpg'))"
      ],
      "metadata": {
        "id": "nWkQFMdH50TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_2 = cv2.imread(os.path.join(data_dir, 'army',  'HMS Queen Elizabeth -MoD-.jpg'))"
      ],
      "metadata": {
        "id": "IC9FWvliwYJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(img.shape)\n",
        "print(img_2.shape)"
      ],
      "metadata": {
        "id": "rcvXliNH5wm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPENCV leser bilder som BGR, matplotlib forventer RGB\n",
        "plt.imshow(img)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # Konverterer BGR til RGB\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KPME_BgF53YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Funksjon for å fjerne potensielle kjipe filer, som vi ikke trenger ###\n",
        "\n",
        "for image_class in os.listdir(data_dir):\n",
        "    for image in os.listdir(os.path.join(data_dir, image_class)):\n",
        "        image_path = os.path.join(data_dir, image_class, image)\n",
        "        try:\n",
        "            img = cv2.imread(image_path)\n",
        "            tip = imghdr.what(image_path)\n",
        "            if tip not in image_exts:\n",
        "                print('Image not in ext list {}'.format(image_path))\n",
        "                os.remove(image_path)\n",
        "        except Exception as e:\n",
        "            print('Issue with image {}'.format(image_path))\n",
        "            #os.remove(image_path)"
      ],
      "metadata": {
        "id": "kS19eboN57R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Laste inn data'en\n",
        "Sjekk ut `tf.data.Dataset`, som vi kommer til å bruke mye her. Tensorflow dokumentasjon, til dem som skal gjøre bildeklassifisering i prosjektet finnes [her](https://www.tensorflow.org/api_docs/python/tf/data/Dataset)!"
      ],
      "metadata": {
        "id": "qvOGQ_1G6CAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "G-rJUnWG6EJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dette her er gull - tf.keras.utils.image_dataset_from_directory er fantastisk for bildeklassifisering\n",
        "data = tf.keras.utils.image_dataset_from_directory(data_dir)"
      ],
      "metadata": {
        "id": "xBBoEaIr6GN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kjøre denne kodeblokken for å se hva vi kan konfigurere!\n",
        "tf.keras.utils.image_dataset_from_directory??"
      ],
      "metadata": {
        "id": "kLufr0DlSbHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle (stokking av dataene)\n",
        "data_iterator = data.as_numpy_iterator()"
      ],
      "metadata": {
        "id": "lEce3iwQ6Hip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Får en ny batch fra vår \"iterator\" - \"vi henter en batch\"\n",
        "batch = data_iterator.next()\n",
        "\n",
        "# Denne batch'en består av bilder (i numpy format), og labels/merkinger (0 or 1, army/not-army)"
      ],
      "metadata": {
        "id": "-T2-rw5I6KYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(batch)"
      ],
      "metadata": {
        "id": "E4xXy3dvTIud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se på shape til ett bilde\n",
        "batch[0].shape"
      ],
      "metadata": {
        "id": "XAbn75uhTRmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aksessere bildene (images)\n",
        "batch[0]\n",
        "\n",
        "# Aksessere labels\n",
        "batch[1]"
      ],
      "metadata": {
        "id": "FYfzUmtSxRbw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 = Army (militære) boats\n",
        "# 1 = Civilian (sivile) boats\n",
        "\n",
        "fig, ax = plt.subplots(ncols=4, figsize=(20,20))\n",
        "for idx, img in enumerate(batch[0][:4]):\n",
        "    #ax[idx].imshow(img)\n",
        "    ax[idx].imshow(img.astype(int))\n",
        "    ax[idx].title.set_text(batch[1][idx])"
      ],
      "metadata": {
        "id": "sWN84aa96OIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M0if-2SL13lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Klassifisering\n",
        "Vi har tidligere snakket om forskjellen mellom *regresjon* og *klassifikasjon*, her gjør vi altså sistnevnte.\n",
        "\n",
        "Som vi kan se over, så representerer '0' militære skip og '1' ikke-militære. Det som er fint med koden vi presenterer her er at dette kan i prinsippet trenes for all mulig slags use-case'r med binær bildeklassifisering."
      ],
      "metadata": {
        "id": "x7cK8b_n6RI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selve bildene er hvor, key = 0\n",
        "batch[0]"
      ],
      "metadata": {
        "id": "QXF4Mvu26Qdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels er i key = 1 (altså, om bildene av skipene er sivile eller militære)\n",
        "batch[1]"
      ],
      "metadata": {
        "id": "35Bm6NmQ6sNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Siden batch[0] er bildene våre, vil batch[0].shape gi (#number of images, 256, 256, 3) ---> 3 kanaler=fargebilde.\n",
        "# Så hvis vi ser på batch[0].min() og batch[0].max() - vil de returnere henholdsvis 0.0 and 255.0\n",
        "batch[0].shape"
      ],
      "metadata": {
        "id": "wm3pex-V6x82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0].min()"
      ],
      "metadata": {
        "id": "08dGwV9HyIWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch[0].max()"
      ],
      "metadata": {
        "id": "BPxIf9VByKxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Husk når vi diskuterte *rank-3 tensorer*, da det er tre matriser *stakket* over hverandre. Derfor snakker vi ofte om RGB, da det er et *lag*/matrise per farge.\n",
        "\n",
        "![Bilde](https://miro.medium.com/v2/resize:fit:1400/1*8pX8Zt2PvIswXv3JY5_AWg.png)\n"
      ],
      "metadata": {
        "id": "BXaibsB360Vb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Når vi bruker dyp-læringsmodeller, bør verdiene vi jobber med (ideelt sett) være så små som mulig!\n",
        "Dette gjøres for de da går *optimaliseringen* MYE fortere. Da kan vi normalisere, det gjør vi ved å dele alle bilde-verdiene på $255$, kall disse $x_i$, og da vil vi få normaliserte verdier - $x_i* \\in[0, 1]$.\n",
        "\n",
        "Dette kalles i *rescaling* eller *min-max normalisering* og kan uttrykkes matematisk:\n",
        "$$x_{i*}=\\frac{x_i-min(\\mathbf{x})}{max(\\mathbf{x})-min(\\mathbf{x})}$$\n",
        "\n",
        "I dette tilfellet er $min(\\mathbf{x})=0$ og $max(\\mathbf{x})=255$.\n"
      ],
      "metadata": {
        "id": "Y08OBQTf7g_u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uansett, det viktige her er at da vil optimalisering gjennom 'ADAM' eller 'Stochastic Gradient Decent' (som diskutert i forelesning 2), vil gå betydelig fortere."
      ],
      "metadata": {
        "id": "Caio0dZU9C05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Her skalerer vi dataen vår til å være mellom 0 og 1.\n",
        "# data.map funker bra for transformasjon av data.\n",
        "# lambda funksjonen lar oss skalerer bildet, altså x - og lar y være som den er.\n",
        "data = data.map(lambda x,y: (x/255, y))"
      ],
      "metadata": {
        "id": "QSUSidCZ7Px8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I koden over vil skalere bildene $x$ med å dele på $255$, slik at hver piksel består av en verdi mellom $0$ og $255$. Men $y$ forblir den samme, som er $0$ eller $1$, basert på om bilde er sivilt eller et militært skip."
      ],
      "metadata": {
        "id": "qWEuW02hrWd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Her ser vi at dataene er normalisert, altså mellom 0 og 1.\n",
        "data.as_numpy_iterator().next()"
      ],
      "metadata": {
        "id": "4z2F6ct09auM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Splite data inn i trening, validering og test sett."
      ],
      "metadata": {
        "id": "LJ3JF-IO9inj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "6YzkJnL0VkHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Dette splitter data inn i trening, validering og test. ###\n",
        "\n",
        "train_size = int(len(data)*.7)\n",
        "val_size = int(len(data)*.2)\n",
        "test_size = int(len(data)*.1)"
      ],
      "metadata": {
        "id": "70zip3IG9dPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Så her får vi opp hvor mange batcher vi har i treningsdataene, hvor batch_size ble satt lenger oppe\n",
        "train_size"
      ],
      "metadata": {
        "id": "z4Z3itbp9mLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Så her får vi opp hvor mange batcher vi har i valideringsdataene, hvor batch_size ble satt lenger oppe\n",
        "val_size"
      ],
      "metadata": {
        "id": "GmWxgp-X1St1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_size"
      ],
      "metadata": {
        "id": "QQJvJb461VGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Her bruker jeg train og skip metoder fra tensorflow for å sortere data. Her er det viktig at dataene allered er shuffled. ###\n",
        "\n",
        "train = data.take(train_size)\n",
        "val = data.skip(train_size).take(val_size)\n",
        "test = data.skip(train_size+val_size).take(test_size)"
      ],
      "metadata": {
        "id": "a4D6W5s89rSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nå kan vi bygge vår bilde-klassifiseringsmodell!"
      ],
      "metadata": {
        "id": "pR9ycpf79ypi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "Kxh2JmeE9x6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
      ],
      "metadata": {
        "id": "EH4AxnyW9vyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vi lager en sekvensiell modell, og legger på lag ved hjelp av 'model.add'-metoden.\n",
        "model = Sequential()"
      ],
      "metadata": {
        "id": "b41E_fqW97Zl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Så her bygger vi vår faktiske modell ###\n",
        "\n",
        "# There are the Convolutional blocks, one flatten layer and two dense layers.\n",
        "\n",
        "# This adds a 2D Convolutional layers - sequantially. The input is a color-image.\n",
        "# 16 filters, 3x3 pixels in size, and a stride of 1 pixel. This is ML architecture.\n",
        "# ReLu activation function, outputs will be passed through a ReLu function! Will\n",
        "# capture non-linear patterns in our data, which is great and a huge application of ML:-)\n",
        "# image shape is 256x256 images, and three layers/channels deep (because its color images).\n",
        "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256,256,3)))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# 32 filter.\n",
        "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# 16 filters\n",
        "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
        "model.add(MaxPooling2D())\n",
        "\n",
        "# Here we flatten the data\n",
        "model.add(Flatten())\n",
        "\n",
        "# Now we have the flatten layer connected to 256 neurons.\n",
        "model.add(Dense(512, activation='relu'))\n",
        "\n",
        "# Single dense layer, and use sigmoid activation function to return 0 or 1 - using 0.5 as a threshold.\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "7qNBchos986o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Her bruker vi opitimzer='adam', men den kan endres på!\n",
        "# Loss er 'binary cross entropy', og vi får tilbake accuracy (fra en conf. matrix).\n",
        "model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "WNKOgISr9_Q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we get the summary of our NN is doing!\n",
        "# So max_pooling2D dont add any parameters, as you can see.\n",
        "# 30x30x16 = 14400 - when we flatten our data.\n",
        "# 257 in the end, is 256 + the bias term.\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "DPnNCu-C-BCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nå kan vi begynne å *trene*"
      ],
      "metadata": {
        "id": "-I2-K7Yu-EdB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logdir='logs'"
      ],
      "metadata": {
        "id": "XOsdV0nH-Cor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nice to save our model, and log our training.\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "Uvce4k8h-IPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se på training data\n",
        "train"
      ],
      "metadata": {
        "id": "2UzbEtd_y7Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.fit is for training our model. Epoch, one epoch is one run over our entire\n",
        "# training data. And we also going to iterate through our validation data.\n",
        "# and we load our callbacks, to look at our training process later.\n",
        "hist = model.fit(train, epochs=20, batch_size=1, validation_data=val, callbacks=[tensorboard_callback])"
      ],
      "metadata": {
        "id": "59H2-2HS-KST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vi plotter hvordan treningen går"
      ],
      "metadata": {
        "id": "XKy-9pl1-OZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se på vår performance for training og validation.\n",
        "hist.history"
      ],
      "metadata": {
        "id": "FRFfUg2T-OB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
        "plt.plot(hist.history['val_loss'], color='orange', label='val_loss')\n",
        "fig.suptitle('Loss', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HClHKXjd-MK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
        "plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')\n",
        "fig.suptitle('Accuracy', fontsize=20)\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SYFZMLcM-We5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Nå kan vi evalurer modellen vår\n",
        "Dette gjør vi altså ved å teste modellen på det **u-sette** test settet!"
      ],
      "metadata": {
        "id": "l4CTkrya-YSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
      ],
      "metadata": {
        "id": "bK3LG0rm-eci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre = Precision()\n",
        "re = Recall()\n",
        "acc = BinaryAccuracy()"
      ],
      "metadata": {
        "id": "0WGur3xk-gNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in test.as_numpy_iterator():\n",
        "    X, y = batch\n",
        "    yhat = model.predict(X)\n",
        "    pre.update_state(y, yhat)\n",
        "    re.update_state(y, yhat)\n",
        "    acc.update_state(y, yhat)"
      ],
      "metadata": {
        "id": "BX7Euzfe-htQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pre.result(), re.result(), acc.result())"
      ],
      "metadata": {
        "id": "F4_SOiUT-jNu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## La oss ta en tilfeldig test av et nytt bilde"
      ],
      "metadata": {
        "id": "ViLp0HFk-oYh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "img = cv2.imread(os.path.join(data_dir, 'army', '1647297548254.jpg'))\n",
        "#plt.imshow(img)\n",
        "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)) # Convert BGR to RGB\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nw-M6XQo-mc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resize = tf.image.resize(img, (256,256))\n",
        "plt.imshow(resize.numpy().astype(int))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2-FRyCcj-vuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we normalize the data by dividing the 'resize' image by 255, to be in the scale [0, 1] --> because then ML stuff goes easier and faster.\n",
        "yhat = model.predict(np.expand_dims(resize/255, 0))"
      ],
      "metadata": {
        "id": "k9h6Qqc6-y-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yhat"
      ],
      "metadata": {
        "id": "yyVZV0x8-0PO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if yhat > 0.5:\n",
        "    print(f'Predicted class is non-Army')\n",
        "else:\n",
        "    print(f'Predicted class is Army')"
      ],
      "metadata": {
        "id": "XJpkUWBh-1Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WreRlzrh_rU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eksempelet fra sist gang - MNIST"
      ],
      "metadata": {
        "id": "guxFLlqsWyyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Se på denne!](https://adamharley.com/nn_vis/cnn/2d.html)"
      ],
      "metadata": {
        "id": "uDOD_-7zW8su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Kode eksempel - Convolutional Neural Networks**\n",
        "Her er et kode-eksempel som bruker et spesielt type nettverk, CNN, dette vil vi ser mer på i forelesning 5."
      ],
      "metadata": {
        "id": "H1tBXU1yjp4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "cni1ZR0644Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Laster inn MNIST-datasettet (håndskrevne siffer).\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normaliserer bildene til verdier i området [0, 1] ved å dele på 255.\n",
        "# Dette gjør at pikselverdiene, som opprinnelig er i området [0, 255], skaleres til flyttall mellom 0 og 1.\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255"
      ],
      "metadata": {
        "id": "PAoS1op4RaJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Laster inn MNIST-datasettet (håndskrevne siffer).\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normaliserer bildene til verdier i området [0, 1] ved å dele på 255.\n",
        "# Dette gjør at pikselverdiene, som opprinnelig er i området [0, 255], skaleres til flyttall mellom 0 og 1.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# Endrer formen på bildene fra (num_samples, 28, 28) til (num_samples, 28, 28, 1).\n",
        "# Den ekstra dimensjonen (1) representerer antall kanaler (her gråskala), hadde den vært satt til (3) har vi fargebilder\n",
        "# da de har tre fargekanaler RGB (Rød, Grønn, Blå).\n",
        "x_train = x_train.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.reshape((-1, 28, 28, 1))\n",
        "\n",
        "#Obs: Den første \"-1\" i reshape() lar NumPy automatisk beregne antall eksempler (num_samples).\n",
        "\n",
        "\n",
        "# One-hot encoder etikettene (klassene) slik at hver etikett blir representert som en vektor med 10 elementer.\n",
        "# Eksempel: Hvis en etikett er 3, blir den representert som [0, 0, 0, 1, 0, 0, 0, 0, 0, 0].\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "5zqu1vmt77BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Når du setter den første dimensjonen til `-1`, vil `reshape()`-funksjonen fra NumPy automatisk finne ut hvor mange bilder det er, basert på størrelsen på resten av dimensjonene $(28, 28, 1)$. På denne måten slipper du å manuelt spesifisere antall bilder `num_samples()` (Men, her vet vi at det er 60.000 bilder i treningsdataene - fra MNIST)."
      ],
      "metadata": {
        "id": "gZc_3wFTAkEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importere nødvendige biblioteker fra TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "\n",
        "# Lager en sekvensiell modell\n",
        "model = Sequential([\n",
        "    # Første konvolusjonslag\n",
        "    # Bruker 32 filtre av størrelse (3, 3), aktivert med ReLU, og forventer en inputform av (28, 28, 1) - altså våre gråskalabilder.\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "\n",
        "    # Maksimal pooling-lag som reduserer dimensjonaliteten til funksjonskartene.\n",
        "    # Bruker en pooling størrelse på (2, 2), noe som halverer både bredde og høyde.\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Dropout-lag for å forhindre overfitting ved tilfeldig å sette 25% av nevronene til null under trening.\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Andre konvolusjonslag med 64 filtre, fortsatt med ReLU-aktivering.\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Ny maksimal pooling-lag for ytterligere dimensjonsreduksjon.\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Ytterligere dropout-lag for å forhindre overfitting, denne gangen med 25%.\n",
        "    Dropout(0.25),\n",
        "\n",
        "    # Flatten-lag som konverterer de 2D-funksjonskartene til 1D-vektorer.\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    # Første Dense-lag med 128 nevroner og ReLU-aktivering, som fullstendig kobler til forrige lag.\n",
        "    Dense(128, activation='relu'),\n",
        "\n",
        "    # Dropout-lag for å hindre overfitting i dette laget også, nå med 50%.\n",
        "    Dropout(0.5),\n",
        "\n",
        "    # Utgangslag med 10 nevroner som representerer de 10 klassene, aktivert med softmax for å få sannsynligheter.\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Modellstrukturen er nå definert. Den kan kompileres og trenes på datasett etterpå."
      ],
      "metadata": {
        "id": "WKegqxow8CB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ojln13iK8FhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=10)"
      ],
      "metadata": {
        "id": "l6fJXjO-8GzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_accuracy}: Test loss: {test_loss}')"
      ],
      "metadata": {
        "id": "rkUKlNAZ8IH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Her ser vi at vi har fått en test accuracy på over $99$%!\n",
        "Her har vi brukt en annen form for nevrale nettverk, kalt *Convolutional Neural Networks* - som vi vil se mer på i forelesning 5!"
      ],
      "metadata": {
        "id": "5su5nR9IB90w"
      }
    }
  ]
}